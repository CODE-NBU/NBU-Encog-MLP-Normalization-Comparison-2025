// clear && astyle --recursive --style=java --indent=tab *.java && gradle build && gradle run

/*
 * This source file was generated by the Gradle 'init' task
 */
package org.example;

import java.util.Arrays;

import org.encog.engine.network.activation.ActivationLinear;
import org.encog.engine.network.activation.ActivationTANH;
import org.encog.ml.data.MLData;
import org.encog.ml.data.MLDataSet;
import org.encog.ml.data.basic.BasicMLData;
import org.encog.ml.data.basic.BasicMLDataSet;
import org.encog.ml.data.temporal.TemporalMLDataSet;
import org.encog.neural.networks.BasicNetwork;
import org.encog.neural.networks.layers.BasicLayer;
import org.encog.neural.networks.training.propagation.resilient.ResilientPropagation;
import org.encog.neural.networks.training.Train;
import org.encog.util.arrayutil.NormalizationAction;
import org.encog.util.arrayutil.NormalizedField;
import org.encog.util.simple.EncogUtility;

/*
1	2	3	4	5	6	7	8	9	10	11	12	13	14	15	16	17	18	19	20	21	22	23	24	25	26
11	12	14	15	16	17	18	18	19	19	20	20	20	20	20	19	19	18	17	16	15	14	13	11	10	9
*/

public class App {
	private static int epoches = 1_000;
	
	// Sample time series data (e.g., previous 3 values to predict the next value)
	private static double[][] rawInput = {
		{11,12,14,15,16,17,18,18,19,19,20,20,20,20,20,19,19,18,17,16},
		{12,14,15,16,17,18,18,19,19,20,20,20,20,20,19,19,18,17,16,15},
		{14,15,16,17,18,18,19,19,20,20,20,20,20,19,19,18,17,16,15,14},
		{15,16,17,18,18,19,19,20,20,20,20,20,19,19,18,17,16,15,14,13},
		{16,17,18,18,19,19,20,20,20,20,20,19,19,18,17,16,15,14,13,11},
	};

	private static double[][] rawOutput = {
		{15},
		{14},
		{13},
		{11},
		{10},
	};

	private static double[] testInput = {17,18,18,19,19,20,20,20,20,20,19,19,18,17,16,15,14,13,11,10};

	public static void main1(String[] args) {
		// Create dataset
		MLDataSet trainingSet = new BasicMLDataSet(rawInput, rawOutput);

		// Define the neural network
		BasicNetwork network = new BasicNetwork();
		network.addLayer(new BasicLayer(null, true, 20));  // Input layer with 3 neurons
		network.addLayer(new BasicLayer(new ActivationTANH(), true, 15)); // Hidden layer with TANH activation
		network.addLayer(new BasicLayer(new ActivationLinear(), false, 1));  // Output layer (Linear activation)
		network.getStructure().finalizeStructure();
		network.reset();

		// Train the network using Resilient Propagation
		Train train = new ResilientPropagation(network, trainingSet);

		int epoch = 1;
		do {
			train.iteration();
			System.out.println("Epoch #" + epoch + " Error: " + train.getError());
			epoch++;
		} while (train.getError() > 0.001 && epoch <= epoches);
		train.finishTraining();

		// Testing the network with a new input
		MLData inputData = new BasicMLData(testInput);
		MLData outputData = network.compute(inputData);

		System.out.println("Prediction for input "+ Arrays.toString(testInput) +": " + outputData.getData(0));
	}

	public static void main2(String[] args) {
		// Define the normalization range
		double normalizationLow = -1.0;
		double normalizationHigh = 1.0;

		// Normalizers for input and output data
		NormalizedField inputNormalizer = new NormalizedField(
		    NormalizationAction.Normalize, null,
		    30.0, 0.0,  // max, min of the dataset (update if dataset changes)
		    normalizationHigh, normalizationLow);

		NormalizedField outputNormalizer = new NormalizedField(
		    NormalizationAction.Normalize, null,
		    30.0, 0.0,
		    normalizationHigh, normalizationLow);

		// Normalize input and output data
		double[][] input = new double[rawInput.length][rawInput[0].length];
		double[][] output = new double[rawOutput.length][rawOutput[0].length];

		for (int i = 0; i < rawInput.length; i++) {
			for (int j = 0; j < rawInput[i].length; j++) {
				input[i][j] = inputNormalizer.normalize(rawInput[i][j]);
			}
			output[i][0] = outputNormalizer.normalize(rawOutput[i][0]);
		}

		// Create dataset
		MLDataSet trainingSet = new BasicMLDataSet(input, output);

		// Define the neural network
		BasicNetwork network = new BasicNetwork();
		network.addLayer(new BasicLayer(null, true, 20));  // Input layer with 3 neurons
		network.addLayer(new BasicLayer(new ActivationTANH(), true, 15)); // Hidden layer with TANH activation
		network.addLayer(new BasicLayer(new ActivationTANH(), false, 1));  // Output layer (Linear activation)
		network.getStructure().finalizeStructure();
		network.reset();

		// Train the network using Resilient Propagation
		Train train = new ResilientPropagation(network, trainingSet);

		int epoch = 1;
		do {
			train.iteration();
			System.out.println("Epoch #" + epoch + " Error: " + train.getError());
			epoch++;
		} while (train.getError() > 0.001 && epoch <= epoches);
		train.finishTraining();

		// Normalize the new input
		double[] newInput = new double[testInput.length];
		for (int i = 0; i < testInput.length; i++) {
			newInput[i] = inputNormalizer.normalize(testInput[i]);
		}

		// Predict the output
		MLData inputData = new BasicMLData(newInput);
		MLData outputData = network.compute(inputData);

		// Denormalize the output
		double predictedNormalized = outputData.getData(0);
		double predictedValue = outputNormalizer.deNormalize(predictedNormalized);

		System.out.println("Prediction for input "+ Arrays.toString(testInput) +": " + predictedValue);
	}

	public static void main(String[] args) {
		main1(args);
		main2(args);
	}
}
